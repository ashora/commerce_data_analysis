# 项目问题
## 需要好好考虑的问题

#### 1. 经过清洗后的数据最初准备放在HBase上，而业务上要求对某段时间范围进行统计分析，因此对rowKey设计上存在难度，为了避免连续时间戳导致热点问题，难免要牺牲读取效率。经过和数据直接存储在HDFS进行对比，发现HDFS上效率要更高一些，按天的维度批量读取数据，HDFS效率更高。

#### 2. 多个RDD分区同时创建Dao层的类，连接数据库，需要控制连接数量。
自定义了一个数据库连接池，连接的参数通过配置文件从外部读取，然后根据连接池大小初始化连接，存储在同步队列blockQuene中。

接着封装一个DBUtil类，所有的增删改查操作都先从连接池获取连接，用完后再放回连接，这样调用的一方就不需要考虑放回连接池了。


#### 3. SparkRDD中去重问题，怎么优化？
* groupBy 和 distinct 效率太低，放弃
* 采用bloomfilter去重，由于算法问题，会丢失数据
* 使用分区排序算子，然后使用DataFrame的dropDuplicates删除重复列，减少shuffle，所以比较快


#### 4. 封装的数据操作函数(比如：添加用户浏览深度的KPI指标)，在每个分区内执行时需要重新创建(Dao层的对象)
比如获取时间、平台组合维度id，经常被复用，所以抽离出来作为一个函数，但是实例化Dao层的对象不应该在函数中，需要在每个分区中，并将Dao层对象作为参数传入。
不能写在算子外面，在每个分区上执行时并不在driver上，在外部实例化实际上对象在driver上。如果数据量少，可以将数据先collect到driver上，再foreach





## 比较简单的问题
#### 1. CDH 5.13.2 java.lang.NoSuchMethodError: org.apache.hadoop.io.nativeio.NativeIO$Windows.createDirectoryWithMode(Ljava/io/File;I)V
保证环境变量里的路径中没有*hadoop.dll*，有就删掉，重启IDEA就好了

#### 2. HiveContext sql() 中执行的sql不能带`;`

#### 3. 分析用户浏览深度指标时，分析后的结果都是单行，需要根据同一维度下分组合并。
使用`collect_set`或者`collect_list`将多行指标转为一行，再通过`concat_ws`将数据拼接成一个字符串
